{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8c5a5-5886-494e-853c-505123e0ca93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование pdf в каритнку png\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "\n",
    "def convert_pdf_to_high_resolution_images(pdf_path, scale_factor=2):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_number]\n",
    "        \n",
    "        pix = page.get_pixmap(matrix=fitz.Matrix(scale_factor, scale_factor))\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "\n",
    "        output_path = f'image_{page_number + 1}.png'\n",
    "        img.save(output_path, 'PNG')\n",
    "\n",
    "pdf_path = 'test_pas.pdf'\n",
    "convert_pdf_to_high_resolution_images(pdf_path, scale_factor=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b9b05-db2d-4d58-998e-42067ef36e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_rectangular_regions(image_path, output_path='rectangular_regions.jpg'):\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Применение адаптивного порогового преобразования для выделения контуров\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 11, 15)\n",
    "    \n",
    "    # Поиск контуров на изображении\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Создание маски\n",
    "    mask = np.zeros_like(gray)\n",
    "    \n",
    "    # Проход по всем контурам и нарисовать их на маске\n",
    "    for contour in contours:\n",
    "        cv2.drawContours(mask, [contour], 0, (255), thickness=cv2.FILLED)\n",
    "    \n",
    "    # Применение маски к изображению\n",
    "    result = cv2.bitwise_and(image, image, mask=mask)\n",
    "    \n",
    "    # Сохранение изображения с выделенными прямоугольными областями\n",
    "    cv2.imwrite(output_path, result)\n",
    "\n",
    "    # Отображение изображения только с прямоугольными областями\n",
    "    plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    plt.title('Image with Only Rectangular Regions')\n",
    "    plt.show()\n",
    "\n",
    "# Пример использования\n",
    "image_path = 'image_2.png'\n",
    "output_path = 'rectangular_regions.jpg'\n",
    "extract_rectangular_regions(image_path, output_path)\n",
    "print(f\"Прямоугольные области сохранены по пути: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849de1b6-0e81-4760-b069-9eb75e72e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Загрузка и подготовка данных MNIST\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images, valid_images, train_labels, valid_labels = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Нормализация значений пикселей к диапазону [0, 1]\n",
    "train_images, valid_images, test_images = train_images / 255.0, valid_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Создание сети\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Обучение модели\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(valid_images, valid_labels))\n",
    "\n",
    "# Сохранение обученной модели\n",
    "model.save('mnist_digit_recognition_model.h5')\n",
    "\n",
    "# Оценка модели\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc}\")\n",
    "\n",
    "# Визуализация результатов\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Пример распознавания\n",
    "predictions = model.predict(test_images[:5])\n",
    "predicted_labels = [tf.argmax(prediction) for prediction in predictions]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(test_images[i], cmap='gray')\n",
    "    plt.title(f\"Predicted: {predicted_labels[i]}, Actual: {test_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a228a44-0862-4030-8ab4-91afd80d00ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Установка пути к исполняемому файлу Tesseract OCR\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    _, binary = cv2.threshold(img, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    binary = binary / 255.0\n",
    "\n",
    "    return binary\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Входной слой LSTM\n",
    "    model.add(LSTM(128, input_shape=input_shape, return_sequences=True))\n",
    "\n",
    "    # Полносвязный слой для каждого временного шага\n",
    "    model.add(TimeDistributed(Dense(num_classes, activation='softmax')))\n",
    "\n",
    "    # Объединение результатов\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Общий выходной слой\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, X_train, y_train, epochs=10):\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=64)\n",
    "\n",
    "image_path = 'buf.png'\n",
    "text = pytesseract.image_to_string(Image.open(image_path), lang='rus')\n",
    "print(\"Исходный текст изображения:\")\n",
    "print(text)\n",
    "\n",
    "binary_image = preprocess_image(image_path)\n",
    "\n",
    "input_shape = (binary_image.shape[0], binary_image.shape[1], 1)  # Формат входных данных для LSTM\n",
    "num_classes = 10\n",
    "\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "binary_image_reshaped = np.expand_dims(binary_image, axis=0)\n",
    "\n",
    "# Обучение модели\n",
    "train_model(model, binary_image_reshaped, y_train, epochs=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
